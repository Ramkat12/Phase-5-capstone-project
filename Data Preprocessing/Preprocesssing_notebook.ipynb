{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QfMYNuDUBtRS"
   },
   "source": [
    "# Business understanding\n",
    "Getting feedback form the users is a crutial aspect of growth as it gives a deeper understanding of user sentiment, improves content moderation, and informs product and service improvements. Our project utilizes the Google AI GoEmotions dataset to expand emotion classification datasets, improving chatbot sensitivity, online behavior detection, and customer support. By training neural networks and SVM models to analyze text tonality, we advance emotion analysis in NLP, benefiting stakeholders such as chatbot system providers, online platforms, and customer support departments. This real-world problem of limited sensitivity and understanding is addressed through our project's enhanced emotion analysis, leading to more empathetic interactions, improved content moderation, and optimized customer support, ultimately enhancing user experiences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZWQFP_quLO9-"
   },
   "source": [
    "## Objectives\n",
    "\n",
    "### Main Objective\n",
    "* Expand emotion classification datasets by training models to analyze text tonality using the Google AI GoEmotions dataset.\n",
    "\n",
    "### Specific Objectives:\n",
    "\n",
    "* Enhance chatbot sensitivity by improving the understanding and response to user emotions.\n",
    "* Detect online hazards by identifying potential harmful content through emotional analysis.\n",
    "* Improve customer support by recognizing and addressing user emotions in textual communication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y2OTKccPDBBt"
   },
   "source": [
    "# Data Understanding\n",
    "The Google AI GoEmotions dataset contains labeled comments from Reddit users expressing diverse emotions. This dataset is suitable for training neural networks to analyze text tonality, as it provides a comprehensive emotional spectrum and allows for subtle differentiation among various emotions. The dataset includes detailed emotional annotations and descriptive statistics, facilitating the analysis of emotions in text. While there may be limitations such as potential biases and subjective categorization, the GoEmotions dataset remains valuable for enhancing chatbot sensitivity, detecting online hazards, and improving customer support through the analysis of diverse emotions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "hCwS4Pb2xYCe"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "id": "JeLWSCxAxkfM",
    "outputId": "c55821e6-0ce2-4e0b-b21d-d23c96bb275b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>example_very_unclear</th>\n",
       "      <th>admiration</th>\n",
       "      <th>amusement</th>\n",
       "      <th>anger</th>\n",
       "      <th>annoyance</th>\n",
       "      <th>approval</th>\n",
       "      <th>caring</th>\n",
       "      <th>confusion</th>\n",
       "      <th>curiosity</th>\n",
       "      <th>...</th>\n",
       "      <th>love</th>\n",
       "      <th>nervousness</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pride</th>\n",
       "      <th>realization</th>\n",
       "      <th>relief</th>\n",
       "      <th>remorse</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>eew5j0j</th>\n",
       "      <td>That game hurt.</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eemcysk</th>\n",
       "      <td>&gt;sexuality shouldn’t be a grouping category I...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ed2mah1</th>\n",
       "      <td>You do right, if you don't care then fuck 'em!</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eeibobj</th>\n",
       "      <td>Man I love reddit.</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eda6yn6</th>\n",
       "      <td>[NAME] was nowhere near them, he was by the Fa...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  \\\n",
       "id                                                           \n",
       "eew5j0j                                    That game hurt.   \n",
       "eemcysk   >sexuality shouldn’t be a grouping category I...   \n",
       "ed2mah1     You do right, if you don't care then fuck 'em!   \n",
       "eeibobj                                 Man I love reddit.   \n",
       "eda6yn6  [NAME] was nowhere near them, he was by the Fa...   \n",
       "\n",
       "         example_very_unclear  admiration  amusement  anger  annoyance  \\\n",
       "id                                                                       \n",
       "eew5j0j                 False           0          0      0          0   \n",
       "eemcysk                  True           0          0      0          0   \n",
       "ed2mah1                 False           0          0      0          0   \n",
       "eeibobj                 False           0          0      0          0   \n",
       "eda6yn6                 False           0          0      0          0   \n",
       "\n",
       "         approval  caring  confusion  curiosity  ...  love  nervousness  \\\n",
       "id                                               ...                      \n",
       "eew5j0j         0       0          0          0  ...     0            0   \n",
       "eemcysk         0       0          0          0  ...     0            0   \n",
       "ed2mah1         0       0          0          0  ...     0            0   \n",
       "eeibobj         0       0          0          0  ...     1            0   \n",
       "eda6yn6         0       0          0          0  ...     0            0   \n",
       "\n",
       "         optimism  pride  realization  relief  remorse  sadness  surprise  \\\n",
       "id                                                                          \n",
       "eew5j0j         0      0            0       0        0        1         0   \n",
       "eemcysk         0      0            0       0        0        0         0   \n",
       "ed2mah1         0      0            0       0        0        0         0   \n",
       "eeibobj         0      0            0       0        0        0         0   \n",
       "eda6yn6         0      0            0       0        0        0         0   \n",
       "\n",
       "         neutral  \n",
       "id                \n",
       "eew5j0j        0  \n",
       "eemcysk        0  \n",
       "ed2mah1        1  \n",
       "eeibobj        0  \n",
       "eda6yn6        1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_data = pd.read_csv('go_emotions_dataset.csv',index_col=0)\n",
    "sentiment_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0jPSEID1rPAJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "id": "-ukVc2GVygTj",
    "outputId": "823fb8ec-8285-4b58-e9e2-4369204b3051"
   },
   "outputs": [],
   "source": [
    "sentiment_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DPHDC-0nJ4JN",
    "outputId": "c821708d-f173-40e0-a5c2-f05dbe662c5c"
   },
   "outputs": [],
   "source": [
    "sentiment_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BBuw67UHJ9BG",
    "outputId": "f70fb3d0-f85c-48fb-8de2-5ff4fca753ac"
   },
   "outputs": [],
   "source": [
    "sentiment_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QNPw0j0kKHii"
   },
   "source": [
    "There are 211225 rows and 31 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OtZMWVlxKYvE",
    "outputId": "9bd71a9f-3d70-4cee-d82e-ecacfc2ce475"
   },
   "outputs": [],
   "source": [
    "# Checking for mssing values\n",
    "sentiment_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 887
    },
    "id": "grY77D4AX4c1",
    "outputId": "4ac60b45-efa1-47e4-d967-c9f019f9ef00"
   },
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicates = sentiment_data[sentiment_data.duplicated()]\n",
    "duplicates_df = pd.DataFrame(duplicates, columns = sentiment_data.columns)\n",
    "duplicates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 872
    },
    "id": "xG3nDJv1u17I",
    "outputId": "98afabf0-72b6-4d16-b7f5-76dae50d04ca"
   },
   "outputs": [],
   "source": [
    "duplicates_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vlxwZ9_mu2HY"
   },
   "source": [
    "Duplicated data was not dropped text might be the same though emotions are different within the row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GCkQONXKYDYG",
    "outputId": "2f43d5c5-928c-4c02-939d-11fcd7111589"
   },
   "outputs": [],
   "source": [
    "sentiment_data['text'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploring patterns and trends in the dataset for the emotions columns \n",
    "# Summary statistics\n",
    "summary_stats = sentiment_data.describe()\n",
    "\n",
    "# Correlation matrix\n",
    "correlation_matrix = sentiment_data.corr()\n",
    "\n",
    "# Print the results\n",
    "print(\"Summary Statistics:\")\n",
    "print(summary_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCorrelation Matrix:\")\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = sentiment_data['example_very_unclear'].value_counts()\n",
    "value_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrences of each value in the example_very_unclear column\n",
    "unclear_counts = sentiment_data['example_very_unclear'].value_counts()\n",
    "\n",
    "# Plot the counts\n",
    "unclear_counts.plot(kind='bar', figsize=(8, 6))\n",
    "value_counts.plot.bar(color=['blue', 'orange'])\n",
    "plt.xlabel('Unclear Label')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Count of Unclear Labels')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This column indicated whether the annotator marked the example as being very unclear or difficult to label (in this case they did not choose any emotion labels).True means no emotions were recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirming no emotions were recorded\n",
    "filtered_data = sentiment_data[sentiment_data['example_very_unclear'] == True]\n",
    "filtered_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Droping records that have ['example_very_unclear'] == True \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_df = sentiment_data[sentiment_data['example_very_unclear'] != True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a copy of the text column \n",
    "# Rename the existing 'text' column to 'original_text'\n",
    "sentiments_df.rename(columns={'text': 'original_text'}, inplace=True)\n",
    "\n",
    "# Create a new column 'text' as a copy of 'original_text' and insert it next to 'original_text'\n",
    "sentiments_df.insert(sentiments_df.columns.get_loc('original_text') + 1, 'text', sentiments_df['original_text'].copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_rows = sentiments_df[sentiments_df.duplicated()]\n",
    "duplicate_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text might be duplicated though ID are different or in instances where IDs are same giving different responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many emotions can be in one text record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouping the emotions into a set\n",
    "emotions = set(sentiments_df.columns[2:])\n",
    "emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_emotions(row):\n",
    "    emotion_list = [emotion for emotion, value in row.items() if value == 1]\n",
    "    return ', '.join(emotion_list)\n",
    "    \n",
    "\n",
    "# Create a new column 'listed_emotions' to store the individual emotions per row\n",
    "sentiments_df['listed_emotions'] = sentiments_df.apply(assign_emotions, axis=1)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(sentiments_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a DataFrame called df with 'ID' set as the index\n",
    "specific_id = 'eew5j0j'\n",
    "\n",
    "# Using loc to access the record with the specific ID\n",
    "specific_record = sentiments_df.loc[specific_id]\n",
    "\n",
    "# Printing the specific record\n",
    "print(specific_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a DataFrame called sentiments_df with a 'listed_emotions' column\n",
    "sentiments_df['emotion_count'] = sentiments_df['listed_emotions'].str.split(', ').apply(lambda x: len(x))\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(sentiments_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lowercasing the text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiments_df['text'] = sentiments_df['text'].str.lower()\n",
    "sentiments_df = sentiments_df.copy()\n",
    "sentiments_df['text'] = sentiments_df['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "sentiments_df['text'] = sentiments_df['text'].str.replace('[{}]'.format(string.punctuation), '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a column to hold emojis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install demoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import demoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the emoji dictionary\n",
    "demoji.download_codes()\n",
    "\n",
    "# Function to extract emojis from text\n",
    "def extract_emojis(text):\n",
    "    emojis = demoji.findall(text)\n",
    "    return ''.join(emojis.keys())\n",
    "\n",
    "# Assuming you have a DataFrame with a 'text' column called sentiments_df\n",
    "sentiments_df['emojis'] = sentiments_df['text'].apply(extract_emojis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a DataFrame called df with 'ID' set as the index\n",
    "specific_id = 'ee0sak1'\n",
    "\n",
    "# Using loc to access the record with the specific ID\n",
    "specific_record = sentiments_df.loc[specific_id]\n",
    "\n",
    "# Printing the specific record\n",
    "print(specific_record)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install emoji --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a DataFrame called sentiments_df with an 'emojis' column\n",
    "demoji.download_codes()  # Download the emoji dictionary\n",
    "\n",
    "def has_emoji(text):\n",
    "    emojis = demoji.findall(text)\n",
    "    return bool(emojis)\n",
    "\n",
    "emoji_records = sentiments_df[sentiments_df['emojis'].apply(has_emoji)]\n",
    "\n",
    "# Printing the records with emojis\n",
    "print(emoji_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(emoji_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_records.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a DataFrame called sentiments_df with an 'emojis' column\n",
    "demoji.download_codes()  # Download the emoji dictionary\n",
    "\n",
    "# Count the occurrence of each emoji in the 'emojis' column\n",
    "emoji_counts = sentiments_df['emojis'].apply(lambda x: demoji.findall(x)).explode().value_counts()\n",
    "\n",
    "# Select the top 10 most used emojis\n",
    "top_10_emojis = emoji_counts.head(10)\n",
    "\n",
    "# Plot the top 10 emojis\n",
    "plt.figure(figsize=(10, 6))\n",
    "top_10_emojis.plot(kind='barh')\n",
    "plt.xlabel('Emoji')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Top 10 Most Used Emojis')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#try sns to create the visual "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing emojis with corresponding text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_emojis_with_text(text):\n",
    "    # Replace emojis with corresponding text descriptions\n",
    "    text_with_text_emojis = emoji.demojize(text)\n",
    "    \n",
    "    return text_with_text_emojis\n",
    "\n",
    "# Applying the function to the 'text' column in your DataFrame\n",
    "sentiments_df['text'] = sentiments_df['text'].apply(replace_emojis_with_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#'ee0sak1' Id had an emoji in the text retrieving to confirm convertion \n",
    "# Set the maximum width of column 'text' to display the full text\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# Access the 'text' column for a specific ID\n",
    "specific_data = sentiments_df.loc['ee0sak1', 'text']\n",
    "\n",
    "# Print the full text\n",
    "print(specific_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove emoji from the text column\n",
    "def remove_emoji(text):\n",
    "    no_emoji = re.sub(r':[^\\s:]+:', '', text)\n",
    "    return no_emoji\n",
    "\n",
    "# Apply the remove_emoji function to the 'text' column\n",
    "sentiments_df['text'] = sentiments_df['text'].apply(remove_emoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the updated DataFrame\n",
    "sentiments_df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the text using the index\n",
    "text_ = sentiments_df.loc['ee0sak1', 'text']\n",
    "\n",
    "# Display the text\n",
    "print(text_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the sentiments_df to a csv \n",
    "sentiments_df.to_csv('Data/sentiments_df.csv', index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Tokenize the 'text' column\n",
    "sentiments_df['text'] = sentiments_df['text'].apply(word_tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the tokenized text\n",
    "sentiments_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Get the set of stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Remove stop words from the text column\n",
    "sentiments_df['text'] = sentiments_df['text'].apply(lambda x: ' '.join([word for word in ' '.join(x).split() if word.lower() not in stop_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the text without stop words\n",
    "sentiments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the 'text' column\n",
    "sentiments_df['text'] = sentiments_df['text'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('omw-1.4')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a lemmatizer instance\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize the tokenized text column\n",
    "sentiments_df['text'] = sentiments_df['text'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word) for word in x]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the lemmatized text\n",
    "sentiments_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Emotions Categorization*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a column for the labels\n",
    "# Define the mapping of emotions to categories\n",
    "emotion_to_category = {\n",
    "    'admiration': 'positive',\n",
    "    'amusement': 'positive',\n",
    "    'approval': 'positive',\n",
    "    'caring': 'positive',\n",
    "    'curiosity': 'positive',\n",
    "    'excitement': 'positive',\n",
    "    'gratitude': 'positive',\n",
    "    'joy': 'positive',\n",
    "    'love': 'positive',\n",
    "    'optimism': 'positive',\n",
    "    'relief': 'positive',\n",
    "    'surprise': 'positive',\n",
    "    'sadness': 'negative',\n",
    "    'pride': 'negative',\n",
    "    'fear': 'negative',\n",
    "    'embarrassment': 'negative',\n",
    "    'disapproval': 'negative',\n",
    "    'disappointment': 'negative',\n",
    "    'confusion': 'negative',\n",
    "    'annoyance': 'negative',\n",
    "    'anger': 'negative',\n",
    "    'nervousness': 'negative',\n",
    "    'desire': 'negative',\n",
    "    'remorse': 'ambiguous',\n",
    "    'realization': 'ambiguous',\n",
    "    'grief': 'ambiguous',\n",
    "    'disgust': 'ambiguous',\n",
    "    'neutral': 'neutral'\n",
    "}\n",
    "\n",
    "emotions_columns = sentiments_df.columns[3:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotions_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_df['labels'] = sentiments_df[emotions_columns].apply(lambda row: emotion_to_category.get(row.idxmax(), 'unknown'), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "# Create an instance of LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the target column\n",
    "sentiments_df['encoded_labels'] = label_encoder.fit_transform(sentiments_df['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = sentiments_df[['encoded_labels', 'labels']].drop_duplicates().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for value in unique_values:\n",
    "    encoded_label, label = value\n",
    "    print(f\"Encoded Label: {encoded_label}, Label: {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentiments_df['labels'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_df.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorizing Emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grouping the emotions into a set\n",
    "emotions = set(sentiments_df.columns[3:-5])\n",
    "emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_col = ['admiration','amusement','approval','caring','curiosity','excitement','gratitude','joy','love','optimism','relief','surprise']\n",
    "negative_col = ['sadness','pride','fear','embarrassment','disapproval','disappointment','confusion','annoyance','anger','nervousness','desire']\n",
    "ambiguous_col = ['remorse','realization','grief','disgust']\n",
    "neutral_col = ['neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_col = sentiments_df[positive_col]\n",
    "negative_col = sentiments_df[negative_col]\n",
    "ambiguous_col = sentiments_df[ambiguous_col]\n",
    "neutral_col = sentiments_df[neutral_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emotion = pd.DataFrame()\n",
    "df_emotion['emotion'] = list(emotions)\n",
    "df_emotion['group'] = ''\n",
    "df_emotion['group'].loc[df_emotion['emotion'].isin(positive_col)] = 'positive'\n",
    "df_emotion['group'].loc[df_emotion['emotion'].isin(negative_col)] = 'negative'\n",
    "df_emotion['group'].loc[df_emotion['emotion'].isin(ambiguous_col)] = 'ambiguous'\n",
    "df_emotion['group'].loc[df_emotion['emotion'].isin(neutral_col)] = 'neutral'\n",
    "df_emotion.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emotion['group'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emotion.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "temp = sentiments_df[emotions].sum(axis=0) \\\n",
    "    .reset_index() \\\n",
    "    .rename(columns={'index': 'emotion', 0: 'n'}) \\\n",
    "    .merge(df_emotion, how='left', on='emotion') \\\n",
    "    .sort_values('n', ascending=False)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "ax.tick_params(axis='x', rotation=90)\n",
    "palette ={\n",
    "    \"positive\": \"skyblue\", \n",
    "    \"negative\": \"red\", \n",
    "    \"ambiguous\": 'gray',\n",
    "    \"neutral\": 'green'  # Add 'neutral' category and corresponding color\n",
    "}\n",
    "sns.barplot(data=temp, x='n', \n",
    "            y='emotion', hue='group', \n",
    "            dodge=False,\n",
    "            palette=palette,\n",
    "            ax=ax)\n",
    "ax.set_title('Count of emotions appearance')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "temp = temp.groupby('group').agg('sum').reset_index()\n",
    "temp = temp.sort_values('n', ascending=False)\n",
    "\n",
    "ax = sns.barplot(data=temp, x='group', y='n')\n",
    "ax.set_title('Emotions category counts')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_counts = {}\n",
    "for c in positive_col:\n",
    "    emotion_counts[c]  = positive_col[c].value_counts().to_dict()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "emotion_counts_sorted = sorted(emotion_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "x = [item[0] for item in emotion_counts_sorted]\n",
    "y = [item[1] for item in emotion_counts_sorted]\n",
    "\n",
    "fig = go.Figure(data=go.Bar(x=x, y=y))\n",
    "fig.update_layout(\n",
    "    title='Go Emotions',\n",
    "    title_x=0.5,  # Center the title\n",
    "    height=600,\n",
    "    xaxis_title=\"Positive Emotion\",\n",
    "    yaxis_title=\"Number of Texts\",\n",
    "    xaxis_tickangle=45\n",
    ")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_counts = {}\n",
    "for c in negative_col:\n",
    "    emotion_counts[c]  = negative_col[c].value_counts().to_dict()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_counts_sorted = sorted(emotion_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "x = [item[0] for item in emotion_counts_sorted]\n",
    "y = [item[1] for item in emotion_counts_sorted]\n",
    "\n",
    "fig = go.Figure(data=go.Bar(x=x, y=y))\n",
    "fig.update_layout(\n",
    "    title='Go Emotions',\n",
    "    title_x=0.5,  # Center the title\n",
    "    height=600,\n",
    "    xaxis_title=\"Negative Emotion\",\n",
    "    yaxis_title=\"Number of Texts\",\n",
    "    xaxis_tickangle=45\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_counts = {}\n",
    "for c in ambiguous_col:\n",
    "    emotion_counts[c]  = ambiguous_col[c].value_counts().to_dict()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_counts_sorted = sorted(emotion_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "x = [item[0] for item in emotion_counts_sorted]\n",
    "y = [item[1] for item in emotion_counts_sorted]\n",
    "\n",
    "fig = go.Figure(data=go.Bar(x=x, y=y))\n",
    "fig.update_layout(\n",
    "    title='Go Emotions',\n",
    "    title_x=0.5,  # Center the title\n",
    "    height=600,\n",
    "    xaxis_title=\"Ambigous Emotion\",\n",
    "    yaxis_title=\"Number of Texts\",\n",
    "    xaxis_tickangle=45\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_counts = neutral_col.value_counts()\n",
    "neutral_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_df = sentiments_df[['original_text', 'text', 'listed_emotions','emotion_count','labels','encoded_labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Converting notebook to csv for modelling phase*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the sentiments_df to a csv \n",
    "sentiments_df.to_csv('Data/preprocessed_data.csv', index = True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
